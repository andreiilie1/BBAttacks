{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys, os, time\n",
    "# Select GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import gc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
    "# from tensorflow.keras.applications.mobilenet import preprocess_input, MobileNet\n",
    "# from tensorflow.keras.applications.resnet50 import preprocess_input, ResNet50\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_accuracy(y_true, y_pred, k=1):\n",
    "    '''From: https://github.com/chainer/chainer/issues/606\n",
    "    \n",
    "    Expects both y_true and y_pred to be one-hot encoded.\n",
    "    '''\n",
    "    argsorted_y = np.argsort(y_pred)[:,-k:]\n",
    "    return np.any(argsorted_y.T == y_true.argmax(axis=1), axis=0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Define data paths and load data </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"/home/ailie/Repos/BBAttacks/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = os.path.join(BASE_PATH, \"x_val_0_10000.npy\")\n",
    "LABELS_PATH = os.path.join(BASE_PATH, \"y_val.npy\")\n",
    "SYNSET_WORDS_PATH = os.path.join(BASE_PATH, \"synset_words.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_idx_to_name = {}\n",
    "f = open(SYNSET_WORDS_PATH,\"r\")\n",
    "idx = 0\n",
    "for line in f:\n",
    "    parts = line.split(\" \")\n",
    "    keras_idx_to_name[idx] = \" \".join(parts[1:])\n",
    "    idx += 1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_raw = np.load(IMAGES_PATH) # loaded as RGB\n",
    "# didn't upload imagenet data here as it is too large, but it is publicl available\n",
    "# and the experiments are reproducible \n",
    "x_val = preprocess_input(x_val_raw.copy()) # converted to BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.load(LABELS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Load model and only keep a small batch of correctly classified images </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep a few images in memory and drop the others\n",
    "TOTAL_SAMPLE_SIZE = 5000\n",
    "x_val = x_val[:TOTAL_SAMPLE_SIZE]\n",
    "x_val_raw = x_val_raw[:TOTAL_SAMPLE_SIZE]\n",
    "\n",
    "y_val = y_val[:TOTAL_SAMPLE_SIZE]\n",
    "y_val_one_hot = to_categorical(y_val, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 13:06:52.902536: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-10-05 13:06:54.556558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:04:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-10-05 13:06:54.556881: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-10-05 13:06:54.559400: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-10-05 13:06:54.561513: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-10-05 13:06:54.561878: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-10-05 13:06:54.564296: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-10-05 13:06:54.565639: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-10-05 13:06:54.570533: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-10-05 13:06:54.570990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-10-05 13:06:54.571779: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2022-10-05 13:06:54.599389: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2997990000 Hz\n",
      "2022-10-05 13:06:54.601736: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556b9508e560 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-10-05 13:06:54.601753: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-10-05 13:06:54.602052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:04:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-10-05 13:06:54.602085: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-10-05 13:06:54.602106: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-10-05 13:06:54.602123: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-10-05 13:06:54.602140: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-10-05 13:06:54.602157: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-10-05 13:06:54.602174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-10-05 13:06:54.602191: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-10-05 13:06:54.602533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2022-10-05 13:06:54.602582: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-10-05 13:06:54.773548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-10-05 13:06:54.773573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2022-10-05 13:06:54.773578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2022-10-05 13:06:54.774188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10378 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)\n",
      "2022-10-05 13:06:54.776067: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556b98832f00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-10-05 13:06:54.776081: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = InceptionV3(include_top=True, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 299, 299, 3) for input Tensor(\"input_1:0\", shape=(None, 299, 299, 3), dtype=float32), but it was called on an input with incompatible shape (None, 224, 224, 3).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 13:07:01.849003: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-10-05 13:07:01.996825: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 7s 42ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy: 0.7146\n",
      "Top-3 accuracy: 0.8612\n",
      "Top-5 accuracy: 0.8976\n"
     ]
    }
   ],
   "source": [
    "for k in [1, 3, 5]:\n",
    "    top_k_acc = top_k_accuracy(y_val_one_hot, y_pred, k)\n",
    "    print(f\"Top-{k} accuracy: {top_k_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices of correctly classified images\n",
    "correct_indices = []\n",
    "agreements = np.argmax(y_pred, axis=1) == np.argmax(y_val_one_hot, axis=1)\n",
    "for x in range(len(agreements)):\n",
    "    if agreements[x]:\n",
    "        correct_indices.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SAMPLE_SIZE = 50\n",
    "RANDOM_SEED = 1337\n",
    "\n",
    "import random\n",
    "random.seed(RANDOM_SEED)\n",
    "sample_correct_indices = random.choices(correct_indices, k=RANDOM_SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(x_val_raw[458]/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_indices = range(500)\n",
    "y_val_one_hot_sample = y_val_one_hot[sample_correct_indices]\n",
    "x_val_sample = x_val[sample_correct_indices]\n",
    "x_val_raw_sample = x_val_raw[sample_correct_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 178ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_sample = model.predict(x_val_sample, verbose=1)\n",
    "assert top_k_accuracy(y_val_one_hot_sample, y_pred_sample, k=1) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check there are enough correctly classified images\n",
    "assert len(x_val_sample) == RANDOM_SAMPLE_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Import attack utils </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dropout, MaxPooling2D, Dense, Flatten, BatchNormalization\n",
    "import importlib\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ailie/Repos/BBAttacks/attacks/\")\n",
    "sys.path.append(\"/home/ailie/Repos/BBAttacks/utils/\")\n",
    "\n",
    "import utils\n",
    "from data_manager import load_data\n",
    "\n",
    "# Black Box Attacks\n",
    "import random_noise\n",
    "import EvoStrategyUniformProbs\n",
    "import SimbaWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evolutionary attack</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoba_params = {\n",
    "    \"gen_size\": 15,\n",
    "    \"px_count\": 1\n",
    "}\n",
    "\n",
    "evoba_confs = [{\"gen_size\": x, \"px_count\": y} for x in [5, 10, 15, 20, 30, 60] for y in [1, 2, 4, 8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████████████████████▌                                                                             | 19/50 [03:20<05:15, 10.17s/it]"
     ]
    }
   ],
   "source": [
    "importlib.reload(EvoStrategyUniformProbs)\n",
    "\n",
    "for evoba_params in evoba_confs:\n",
    "    perturbed_images = 0\n",
    "    adv_evo_strategy = {}\n",
    "    failed_indices = []\n",
    "\n",
    "    for index in tqdm(range(RANDOM_SAMPLE_SIZE)):\n",
    "        img = x_val_raw_sample[index]\n",
    "        label = np.argmax(y_val_one_hot_sample[index])\n",
    "\n",
    "        adv_evo_strategy[index] = EvoStrategyUniformProbs.AdversarialPerturbationEvoStraegy(\n",
    "            model=model,\n",
    "            img=img,\n",
    "            label=label,\n",
    "            generation_size=evoba_params[\"gen_size\"], \n",
    "            one_step_perturbation_pixel_count=evoba_params[\"px_count\"],\n",
    "            verbose=False,\n",
    "            zero_one_scale=False,\n",
    "            range_scale_int=True,\n",
    "            preprocess = preprocess_input\n",
    "        )\n",
    "\n",
    "        no_steps = adv_evo_strategy[index].run_adversarial_attack(steps=10000)\n",
    "        if adv_evo_strategy[index].is_perturbed() and no_steps > 0:\n",
    "            perturbed_images += 1\n",
    "\n",
    "        if not adv_evo_strategy[index].is_perturbed():\n",
    "            failed_indices.append(index)\n",
    "\n",
    "    utils.generate_mlflow_logs(\n",
    "        strategy_objects=adv_evo_strategy, \n",
    "        attack_type=utils.AttackType.EVOBA, \n",
    "        unperturbed_images=x_val_raw_sample, \n",
    "        run_name=\"EvoBA\", \n",
    "        experiment_name=\"IMAGENET\",\n",
    "        additional_params=evoba_params,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoba_stats = utils.get_evoba_stats(adv_evo_strategy)\n",
    "utils.print_evoba_stats(evoba_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Prin perturbed pictures util\n",
    "# w=10\n",
    "# h=10\n",
    "# fig=plt.figure(figsize=(20, 9))\n",
    "# fig.tight_layout()\n",
    "# plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=0.1, wspace=0.2)\n",
    "\n",
    "# columns = 5\n",
    "# rows = 2\n",
    "# img_curr = 0\n",
    "# for i in range(1, columns + 1):\n",
    "#     img_indx = fair_indices[imgss[img_curr]]\n",
    "#     initial = (keras_idx_to_name[adv_evo_strategy[img_indx].label])\n",
    "#     if len(initial) > 30:\n",
    "#         initial = initial[:21] + \"\\n\" + initial[21:]\n",
    "#     fig.add_subplot(rows, columns, i)\n",
    "#     plt.title(f\"Original, \\n {initial}\", fontdict={\"size\":18})\n",
    "#     img_start = adv_evo_strategy[img_indx].img.astype(int)\n",
    "#     plt.imshow(img_start)\n",
    "    \n",
    "#     fig.add_subplot(rows, columns, i + 5)\n",
    "    \n",
    "#     img_final = adv_evo_strategy[img_indx].get_best_candidate().astype(int)\n",
    "#     predss = model.predict(np.expand_dims(img_final, axis=0))[0]\n",
    "#     predicted = np.argmax(predss)\n",
    "#     diff = math.sqrt(np.sum((img_final - img_start) **2))\n",
    "#     l2_distance = int((diff/(255)) * 100)/100\n",
    "#     l0_distance = (img_start != img_final).sum()\n",
    "#     final = (keras_idx_to_name[predicted])\n",
    "#     plt.title(f\"Perturbed, \\n {final} L2 distance:{l2_distance}\\n L0 distance:{l0_distance}\", fontdict={\"size\":18})\n",
    "#     plt.imshow(img_final)\n",
    "#     img_curr += 1\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for index_diff in tqdm(np.array(fair_indices)[imgss]):\n",
    "#     print(index_diff)\n",
    "#     initial = (keras_idx_to_name[adv_evo_strategy[index_diff].label])\n",
    "#     img = adv_evo_strategy[index_diff].get_best_candidate().astype(int)\n",
    "#     plt.imshow(img.astype(int))\n",
    "#     predicted = (np.argmax(model.predict(np.expand_dims(img, axis=0))[0]))\n",
    "#     final = (keras_idx_to_name[predicted])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(SimbaWrapper)\n",
    "simba_wrapper = SimbaWrapper.SimbaWrapper(model, x_val_raw_sample, y_val_one_hot_sample, 0.1, \n",
    "                                          max_queries=10000, max_l0_distance=255*255*10, preprocess=preprocess_input,\n",
    "                                          max_value=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 14.42it/s]\n"
     ]
    }
   ],
   "source": [
    "simba_wrapper.run_simba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.9923414 , -0.9939408 , -0.9968935 ],\n",
       "        [-0.9922184 , -0.9935717 , -0.99633986],\n",
       "        [-0.9923414 , -0.9935717 , -0.9960938 ],\n",
       "        ...,\n",
       "        [-0.99701655, -0.99621683, -1.0026144 ],\n",
       "        [-0.99695504, -0.99621683, -1.0024914 ],\n",
       "        [-0.9968935 , -0.9961553 , -1.0021838 ]],\n",
       "\n",
       "       [[-0.9924029 , -0.9939408 , -0.9968935 ],\n",
       "        [-0.9923414 , -0.9936332 , -0.9965244 ],\n",
       "        [-0.9922184 , -0.9935102 , -0.9961553 ],\n",
       "        ...,\n",
       "        [-0.99701655, -0.99627835, -1.0024914 ],\n",
       "        [-0.996832  , -0.9960938 , -1.0022453 ],\n",
       "        [-0.996832  , -0.9960938 , -1.0021223 ]],\n",
       "\n",
       "       [[-0.99215686, -0.99338716, -0.9960938 ],\n",
       "        [-0.99252594, -0.9936947 , -0.9965244 ],\n",
       "        [-0.99215686, -0.99338716, -0.9960323 ],\n",
       "        ...,\n",
       "        [-0.99695504, -0.99621683, -1.0023068 ],\n",
       "        [-0.9968935 , -0.9961553 , -1.0022453 ],\n",
       "        [-0.9968935 , -0.9961553 , -1.0021838 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.9960323 , -0.99818534, -1.0019377 ],\n",
       "        [-0.9961553 , -0.99830836, -1.0019993 ],\n",
       "        [-0.99627835, -0.9984929 , -1.0025529 ],\n",
       "        ...,\n",
       "        [-0.994802  , -0.99701655, -1.0002768 ],\n",
       "        [-0.9948635 , -0.9972011 , -1.0000923 ],\n",
       "        [-0.994925  , -0.9972011 , -1.0005229 ]],\n",
       "\n",
       "       [[-0.9960323 , -0.99818534, -1.0018762 ],\n",
       "        [-0.99621683, -0.99830836, -1.0021223 ],\n",
       "        [-0.99578625, -0.9979392 , -1.0014457 ],\n",
       "        ...,\n",
       "        [-0.99455595, -0.9967089 , -0.99996924],\n",
       "        [-0.994679  , -0.99701655, -1.0001538 ],\n",
       "        [-0.994925  , -0.9972011 , -1.0005229 ]],\n",
       "\n",
       "       [[-0.9959708 , -0.9980623 , -1.0016917 ],\n",
       "        [-0.9954171 , -0.99763167, -1.0007074 ],\n",
       "        [-0.9961553 , -0.99824685, -1.0021223 ],\n",
       "        ...,\n",
       "        [-0.99449444, -0.9967705 , -0.9996617 ],\n",
       "        [-0.9948635 , -0.99707806, -1.0002768 ],\n",
       "        [-0.994679  , -0.99701655, -0.99996924]]], dtype=float32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simba_wrapper.X_modified[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val_sample[0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
