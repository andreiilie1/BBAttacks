{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/andrei/Desktop/Repos/BBAttacks/attacks/\")\n",
    "sys.path.append(\"/Users/andrei/Desktop/Repos/BBAttacks/utils/\")\n",
    "\n",
    "import utils\n",
    "from data_manager import load_data\n",
    "\n",
    "# Black Box Attacks\n",
    "import random_noise\n",
    "import EvoStrategy\n",
    "import SimbaWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras as keras\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cifar_100_classes = [\"apple\", \"aquarium_fish\", \"baby\", \"bear\", \"beaver\", \"bed\", \"bee\", \"beetle\", \"bicycle\", \"bottle\", \"bowl\", \"boy\", \"bridge\", \"bus\", \"butterfly\", \"camel\", \"can\", \"castle\", \"caterpillar\", \"cattle\", \"chair\", \"chimpanzee\", \"clock\", \"cloud\", \"cockroach\", \"couch\", \"cra\", \"crocodile\", \"cup\", \"dinosaur\", \"dolphin\", \"elephant\", \"flatfish\", \"forest\", \"fox\", \"girl\", \"hamster\", \"house\", \"kangaroo\", \"keyboard\", \"lamp\", \"lawn_mower\", \"leopard\", \"lion\", \"lizard\", \"lobster\", \"man\", \"maple_tree\", \"motorcycle\", \"mountain\", \"mouse\", \"mushroom\", \"oak_tree\", \"orange\", \"orchid\", \"otter\", \"palm_tree\", \"pear\", \"pickup_truck\", \"pine_tree\", \"plain\", \"plate\", \"poppy\", \"porcupine\", \"possum\", \"rabbit\", \"raccoon\", \"ray\", \"road\", \"rocket\", \"rose\", \"sea\", \"seal\", \"shark\", \"shrew\", \"skunk\", \"skyscraper\", \"snail\", \"snake\", \"spider\", \"squirrel\", \"streetcar\", \"sunflower\", \"sweet_pepper\", \"table\", \"tank\", \"telephone\", \"television\", \"tiger\", \"tractor\", \"train\", \"trout\", \"tulip\", \"turtle\", \"wardrobe\", \"whale\", \"willow_tree\", \"wolf\", \"woman\", \"worm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Loading model and data </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CIFAR100_VGG_PATH = \"/Users/andrei/Desktop/Repos/cifar-vgg/\"\n",
    "sys.path.append(CIFAR100_VGG_PATH)\n",
    "import cifar100vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(cifar100vgg)\n",
    "model = cifar100vgg.cifar100vgg(train=False)\n",
    "\n",
    "NUM_CLASSES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOAD_DATA = True\n",
    "SAVE_DATA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if LOAD_DATA:\n",
    "    (x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "    y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "    y_test = keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "    \n",
    "    if SAVE_DATA:\n",
    "        np.save(\"x_test.npy\", x_test)\n",
    "        np.save(\"y_test.npy\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('int')\n",
    "x_test = x_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "preds_train = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_train_labels = np.argmax(preds_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_train_labels = np.argmax(y_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc_train = np.mean(true_train_labels == preds_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_labels = np.argmax(preds, axis=1)\n",
    "true_labels = np.argmax(y_test, axis=1)\n",
    "acc = np.sum(pred_labels == true_labels) / len(y_test)\n",
    "print(\"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extracting correctly classified test samples\n",
    "x_test_correct = x_test[pred_labels == true_labels]\n",
    "y_test_correct = y_test[pred_labels == true_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_class_correct_mask = (pred_labels == true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Intermediary layers utils </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_intermediate_outputs(model, batch_input):\n",
    "    intermediate_layer_names = [layer.name for layer in model.model.layers] \n",
    "    \n",
    "    intermediate_layers_model = [\n",
    "        keras.Model(\n",
    "            inputs=model.model.input, \n",
    "            outputs=model.model.get_layer(layer_name).output,\n",
    "        ) for layer_name in intermediate_layer_names\n",
    "    ]\n",
    "    \n",
    "    normalized_batch = model.normalize_production(batch_input)\n",
    "        \n",
    "    intermediate_batch_outputs = [intermediate_layer_model(normalized_batch) for intermediate_layer_model in intermediate_layers_model]\n",
    "    \n",
    "    # return np.array(intermediate_batch_outputs)\n",
    "    return intermediate_batch_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_layer_to_max_rel_change(interm_outputs_1, interm_outputs_2, show=True):\n",
    "    interm_outputs_delta = []\n",
    "    \n",
    "    for layer in range(len(interm_outputs_1)):\n",
    "        interm_outputs_delta.append(interm_outputs_2[layer] - interm_outputs_1[layer])\n",
    "    \n",
    "    layer_to_max_rel_change = []\n",
    "    for layer in range(len(interm_outputs_1)):\n",
    "        max_change_curr_layer = (np.sum(np.abs(interm_outputs_delta[layer][0]))/np.sum(np.abs(interm_outputs_1[layer][0])))\n",
    "        layer_to_max_rel_change.append(max_change_curr_layer)\n",
    "    \n",
    "    if show:\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.plot(layer_to_max_rel_change)\n",
    "        plt.show()\n",
    "    \n",
    "    return layer_to_max_rel_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_outputs(model, batch_input, layer_index):\n",
    "    intermediate_layer_names = [layer.name for layer in model.model.layers] \n",
    "    \n",
    "    layer_name = intermediate_layer_names[layer_index]\n",
    "    \n",
    "    intermediate_layer_model = keras.Model(\n",
    "        inputs=model.model.input, \n",
    "        outputs=model.model.get_layer(layer_name).output,\n",
    "    )\n",
    "    \n",
    "    normalized_batch = model.normalize_production(batch_input)\n",
    "    \n",
    "    intermediate_batch_outputs = intermediate_layer_model(normalized_batch)\n",
    "    \n",
    "    # return np.array(intermediate_batch_outputs)\n",
    "    return intermediate_batch_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Run EvoBA against the neural network </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(EvoStrategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GENERATION_SIZE = 30\n",
    "PIXEL_COUNT = 1\n",
    "STEPS = 80\n",
    "\n",
    "adv_evo_strategy = {}\n",
    "\n",
    "# SIZE = len(x_test_correct)\n",
    "SIZE = 100\n",
    "VERBOSE = False\n",
    "\n",
    "perturbed_images = 0\n",
    "failed_images = 0\n",
    "queries = []\n",
    "\n",
    "\n",
    "for index in tqdm(range(SIZE)):\n",
    "    if test_class_correct_mask[index]:\n",
    "        img = x_test[index]\n",
    "        label = np.argmax(y_test[index])\n",
    "        adv_evo_strategy[index] = EvoStrategy.AdversarialPerturbationEvoStraegy(\n",
    "            model=model,\n",
    "            img=img,\n",
    "            label=label,\n",
    "            generation_size=GENERATION_SIZE, \n",
    "            one_step_perturbation_pixel_count=PIXEL_COUNT,\n",
    "            verbose=VERBOSE,\n",
    "            zero_one_scale=False\n",
    "        )\n",
    "        no_steps = adv_evo_strategy[index].run_adversarial_attack(steps=STEPS)\n",
    "        if adv_evo_strategy[index].is_perturbed() and no_steps > 0:\n",
    "            perturbed_images += 1\n",
    "            queries.append(adv_evo_strategy[index].queries)\n",
    "        else:\n",
    "            failed_images += 1\n",
    "            queries.append(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Plot relative perturbation per layer of the EvoBA adversarial samples </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "interm_outputs_modif = {}\n",
    "interm_outputs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_arrays = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAMPLE_SIZE_INTERM = SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for index_diff in range(RESTART_INDEX, SIZE):\n",
    "for index_diff in tqdm(range(SAMPLE_SIZE_INTERM)):\n",
    "    if test_class_correct_mask[index_diff]:\n",
    "        modif_img = adv_evo_strategy[index_diff].get_best_candidate()\n",
    "        orig_img = x_test[index_diff]\n",
    "\n",
    "        # modif_img_normalized_array = model.normalize_production(np.array([modif_img]).astype(float))\n",
    "        # orig_img_normalized_array = model.normalize_production(np.array([orig_img]).astype(float))\n",
    "\n",
    "        interm_outputs_modif[index_diff] = get_intermediate_outputs(model, np.array([modif_img]).astype(float))\n",
    "        interm_outputs[index_diff] = get_intermediate_outputs(model, np.array([orig_img]).astype(float))\n",
    "\n",
    "        plot_arrays[index_diff] = plot_layer_to_max_rel_change(\n",
    "            interm_outputs[index_diff], \n",
    "            interm_outputs_modif[index_diff],\n",
    "            show=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for index_diff in tqdm(range(RESTART_INDEX, SIZE)):\n",
    "for index_diff in range(SAMPLE_SIZE_INTERM):\n",
    "    if test_class_correct_mask[index_diff]:\n",
    "        plot_arrays[index_diff] = plot_layer_to_max_rel_change(\n",
    "            interm_outputs[index_diff], \n",
    "            interm_outputs_modif[index_diff],\n",
    "            show=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "COLS = 2\n",
    "ROWS = 3\n",
    "\n",
    "FONTSIZE = 32\n",
    "FONTSIZE_AXIS = 28\n",
    "FONTSIZE_LEGEND = 24\n",
    "\n",
    "fig, axs = plt.subplots(ROWS, COLS, figsize=(ROWS * 12,COLS * 10), )\n",
    "fig.tight_layout(pad=15.0)\n",
    "\n",
    "for i in range(ROWS):\n",
    "    for j in range(COLS):\n",
    "        \n",
    "        avg_changes_linear = []\n",
    "        indices_linear = []\n",
    "\n",
    "        avg_changes_activation = []\n",
    "        indices_activation = []\n",
    "        \n",
    "        img_index = list(plot_arrays.keys())[i * COLS + j]\n",
    "        \n",
    "        for index, layer in enumerate(model.model.layers[:-1]):\n",
    "            if layer.name.startswith(\"conv\") or layer.name.startswith(\"dense\"):\n",
    "                avg_changes_linear.append(plot_arrays[img_index][index])\n",
    "                indices_linear.append(index)\n",
    "            elif layer.name.startswith(\"activ\"):\n",
    "                avg_changes_activation.append(plot_arrays[img_index][index])        \n",
    "                indices_activation.append(index)\n",
    "                \n",
    "        axs[i,j].set_title(f\"Image {img_index}\", fontsize=FONTSIZE)\n",
    "        axs[i,j].set_ylim(0, 1.2)\n",
    "        axs[i,j].plot(plot_arrays[img_index][:-1])\n",
    "        axs[i,j].set_xlabel(\"Layer index\", fontsize=FONTSIZE)\n",
    "        axs[i,j].set_ylabel(\"Relative change\", fontsize=FONTSIZE)\n",
    "        \n",
    "        axs[i,j].xaxis.set_tick_params(labelsize=FONTSIZE_AXIS)\n",
    "        axs[i,j].yaxis.set_tick_params(labelsize=FONTSIZE_AXIS)\n",
    "\n",
    "        axs[i,j].scatter(indices_linear, avg_changes_linear, c=\"orange\", label=\"Conv or dense layers\")\n",
    "        axs[i,j].scatter(indices_activation, avg_changes_activation, c=\"red\", label=\"Activation layers\")\n",
    "        axs[i,j].legend(fontsize=FONTSIZE_LEGEND)\n",
    "\n",
    "plt.xticks(fontsize=FONTSIZE_AXIS)\n",
    "plt.yticks(fontsize=FONTSIZE_AXIS)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_changes = np.mean(np.array(list(plot_arrays.values())), axis=0)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_changes_in_layers_list = [model.model.layers[x].get_config() for x in list(reversed(np.argsort(avg_changes)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_changes_linear = []\n",
    "indices_linear = []\n",
    "\n",
    "avg_changes_activation = []\n",
    "indices_activation = []\n",
    "\n",
    "for index, layer in enumerate(model.model.layers[:-1]):\n",
    "    if layer.name.startswith(\"conv\") or layer.name.startswith(\"dense\"):\n",
    "        avg_changes_linear.append(avg_changes[index])\n",
    "        indices_linear.append(index)\n",
    "    elif layer.name.startswith(\"activ\"):\n",
    "        avg_changes_activation.append(avg_changes[index])        \n",
    "        indices_activation.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FONTSIZE = 28\n",
    "FONTSIZE_AXIS = 24\n",
    "FONTSIZE_LEGEND = 24\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.xlabel(\"Layer index\", fontsize=FONTSIZE)\n",
    "plt.ylabel(\"Relative average change\", fontsize=FONTSIZE)\n",
    "plt.xticks(fontsize=FONTSIZE_AXIS)\n",
    "plt.yticks(fontsize=FONTSIZE_AXIS)\n",
    "plt.plot(avg_changes)\n",
    "plt.scatter(indices_linear, avg_changes_linear, c=\"orange\", label=\"Conv or dense layers\")\n",
    "plt.scatter(indices_activation, avg_changes_activation, c=\"red\", label=\"Activation layers\")\n",
    "plt.legend(fontsize=FONTSIZE_LEGEND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Train LGB on intermediary output </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = [model.model.layers[x].get_config()['name'] for x in range(len(model.model.layers))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LAYER_IDX = 40\n",
    "\n",
    "SLICE_SIZE = 200\n",
    "\n",
    "train_features = []\n",
    "for i in tqdm(range(len(x_train) // SLICE_SIZE)):\n",
    "    left = i * SLICE_SIZE\n",
    "    right = left + SLICE_SIZE\n",
    "    batch_layer_outputs = get_layer_outputs(model, x_train[left:right], LAYER_IDX)\n",
    "    batch_layer_outputs = np.reshape(batch_layer_outputs, (SLICE_SIZE, -1))\n",
    "    train_features.append(batch_layer_outputs)\n",
    "\n",
    "train_features = np.vstack(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_stack, X_val, y_train_stack, y_val = train_test_split(train_features, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train_stack = np.argmax(y_train_stack, axis=1)\n",
    "y_val = np.argmax(y_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_OPTUNA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'lambda_l1': 0.8021389627616706, \n",
    "    'lambda_l2': 9.818860936043825, \n",
    "    'num_leaves': 135, \n",
    "    'feature_fraction': 0.6016921652574784, \n",
    "    'bagging_fraction': 0.9902711576251494, \n",
    "    'bagging_freq': 1, \n",
    "    'min_child_samples': 81\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    train_x, test_x, train_y, test_y = X_train_stack, X_val, y_train_stack, y_val\n",
    "    dtrain = lgb.Dataset(train_x, label=train_y)\n",
    " \n",
    "    param = {\n",
    "        'objective': 'multiclass',\n",
    "        'metric': 'multi_logloss',\n",
    "        'num_class': 100,\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'verbose': -1,\n",
    "    }\n",
    "    gbm = lgb.train(param, dtrain, verbose_eval=False)\n",
    "    preds = np.argmax(gbm.predict(test_x), axis=1)\n",
    "    accuracy = sklearn.metrics.accuracy_score(test_y, preds)\n",
    "    return accuracy\n",
    " \n",
    "if RUN_OPTUNA:\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=100, timeout=7200)\n",
    "\n",
    "    print('Number of finished trials:', len(study.trials))\n",
    "    print('Best trial:', study.best_trial.params)\n",
    "    best_params = study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    **best_params,\n",
    "    'objective': 'multiclass',\n",
    "    'metric': 'multi_logloss',\n",
    "    'num_class': 100,\n",
    "    'verbose': -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TUNE_NUM_ITERS = False\n",
    "num_iters_full_train = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TUNE_NUM_ITERS:\n",
    "    dtrain = lgb.Dataset(X_train_stack, y_train_stack)\n",
    "    dval = lgb.Dataset(X_val, y_val)\n",
    "\n",
    "    lgb_stack_interm = lgb.train(params, train_set=dtrain, valid_sets=[dval], early_stopping_rounds=30, num_boost_round=1000, verbose_eval=10)\n",
    "    \n",
    "    num_iters_full_train = lgb_stack_interm.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_stack_full = np.vstack([X_train_stack, X_val])\n",
    "y_train_stack_full = np.concatenate((y_train_stack, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtrain_full = lgb.Dataset(X_train_stack_full, y_train_stack_full)\n",
    "lgb_stack = lgb.train(params, train_set=dtrain_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(np.argmax(lgb_stack.predict(X_val), axis=1) == y_val).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Run stacked model on test data </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LAYER_IDX = 40\n",
    "\n",
    "SLICE_SIZE = 200\n",
    "\n",
    "test_features = []\n",
    "for i in tqdm(range(len(x_test) // SLICE_SIZE)):\n",
    "    left = i * SLICE_SIZE\n",
    "    right = left + SLICE_SIZE\n",
    "    batch_layer_outputs = get_layer_outputs(model, x_test[left:right], LAYER_IDX)\n",
    "    batch_layer_outputs = np.reshape(batch_layer_outputs, (SLICE_SIZE, -1))\n",
    "    test_features.append(batch_layer_outputs)\n",
    "\n",
    "test_features = np.vstack(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_pred_lgb = lgb_stack.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stack_model_correct_test_indices = (np.argmax(test_pred_lgb, axis=1) == np.argmax(y_test, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stack_model_test_accuracy = stack_model_correct_test_indices.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_model_test_total_correct = stack_model_correct_test_indices.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_test_correct_stack = x_test[stack_model_correct_test_indices]\n",
    "y_test_correct_stack = y_test[stack_model_correct_test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StackedModel():\n",
    "    def __init__(self, deep_model, layer_idx, lgb_model):\n",
    "        self.deep_model = deep_model\n",
    "        self.layer_idx = layer_idx\n",
    "        self.lgb_model = lgb_model\n",
    "        \n",
    "        \n",
    "    def predict_intermediary(self, batch_img):\n",
    "        batch_size = len(batch_img)\n",
    "        batch_layer_outputs = get_layer_outputs(self.deep_model, batch_img, self.layer_idx)\n",
    "        batch_layer_outputs = np.reshape(batch_layer_outputs, (batch_size, -1))\n",
    "        return batch_layer_outputs\n",
    "    \n",
    "    def predict(self, batch_img, verbose=False):\n",
    "        batch_layer_outputs = self.predict_intermediary(batch_img)\n",
    "        \n",
    "        lgb_output = self.lgb_model.predict(batch_layer_outputs)\n",
    "        return lgb_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stacked_model = StackedModel(model, LAYER_IDX, lgb_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(model.model.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3> Run EvoBA against the stacked model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adv_evo_strategy_lgb = {}\n",
    "queries_lgb = []\n",
    "perturbed_images_lgb = 0\n",
    "failed_images_lgb = 0\n",
    "\n",
    "for index in tqdm(range(SIZE)):\n",
    "    if stack_model_correct_test_indices[index]:\n",
    "        img = x_test[index]\n",
    "        label = np.argmax(y_test[index])\n",
    "        adv_evo_strategy_lgb[index] = EvoStrategy.AdversarialPerturbationEvoStraegy(\n",
    "            model=stacked_model,\n",
    "            img=img,\n",
    "            label=label,\n",
    "            generation_size=GENERATION_SIZE, \n",
    "            one_step_perturbation_pixel_count=PIXEL_COUNT,\n",
    "            verbose=VERBOSE,\n",
    "            zero_one_scale=False\n",
    "        )\n",
    "\n",
    "        no_steps = adv_evo_strategy_lgb[index].run_adversarial_attack(steps=STEPS)\n",
    "        if adv_evo_strategy_lgb[index].is_perturbed() and no_steps > 0:\n",
    "            perturbed_images_lgb += 1\n",
    "            queries_lgb.append(adv_evo_strategy_lgb[index].queries)\n",
    "        else:\n",
    "            failed_images_lgb += 1\n",
    "            queries_lgb.append(-1)\n",
    "\n",
    "        adv_evo_strategy_lgb[index].run_adversarial_attack(steps=STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.max(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# preds_stacked_model_on_test_correct = np.argmax(stacked_model.predict(x_test_correct_stack), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lgb_acc_on_test_correct = sum(preds_stacked_model_on_test_correct == np.argmax(y_test_correct_stack, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb_acc_on_test_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(lgb_acc_on_test_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extrapolate_total_perturbed_lgb = perturbed_images_lgb / lgb_acc_on_test_correct * stack_model_test_total_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.max(queries_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_queries_succ = np.array(queries)[np.array(queries)>0].mean()\n",
    "avg_queries_succ_lgb = np.array(queries_lgb)[np.array(queries_lgb)>0].mean()\n",
    "\n",
    "print(\n",
    "    \"Stack model perturbed images:\", perturbed_images_lgb, f\"out of {perturbed_images_lgb + failed_images_lgb}\",\n",
    "    \"correctly classified ones\",\n",
    "    f\"i.e {perturbed_images_lgb / (perturbed_images_lgb + failed_images_lgb) * 100}%\"\n",
    ")\n",
    "print(\n",
    "    \"Deep model perturbed images:\", perturbed_images, f\"out of {perturbed_images + failed_images}\",\n",
    "    f\"i.e {perturbed_images / (perturbed_images + failed_images) * 100}%\\n\"\n",
    ")\n",
    "\n",
    "print(\"Stack model avg succ query:\", avg_queries_succ)\n",
    "print(\"Deep model avg succ query:\", avg_queries_succ_lgb, \"\\n\")\n",
    "\n",
    "print(\"Stack model accuracy:\", stack_model_test_accuracy)\n",
    "print(\"Deep model accuracy:\", acc, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Plot perturbed accuracy as a function of queries </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "queries_lgb.sort()\n",
    "queries.sort()\n",
    "\n",
    "queries_lgb_array = np.array(queries_lgb)\n",
    "queries_lgb_array = queries_lgb_array[queries_lgb_array > 0]\n",
    "\n",
    "queries_array = np.array(queries)\n",
    "queries_array = queries_array[queries_array > 0]\n",
    "\n",
    "intermediary_accuracies = []\n",
    "intermediary_lgb_accuracies = []\n",
    "query_thresholds = []\n",
    "\n",
    "for i in range(0, 2000, 50):\n",
    "    curr_perturbed_count = np.sum(queries_array < i)\n",
    "    curr_lgb_perturbed_count = np.sum(queries_lgb_array < i)\n",
    "    \n",
    "    intermediary_accuracies.append((perturbed_images + failed_images - curr_perturbed_count)/SIZE)\n",
    "    intermediary_lgb_accuracies.append((perturbed_images_lgb + failed_images_lgb - curr_lgb_perturbed_count)/SIZE)\n",
    "    query_thresholds.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(query_thresholds, intermediary_accuracies)\n",
    "plt.plot(query_thresholds, intermediary_lgb_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(adv_evo_strategy_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "common_perturbed_indices = []\n",
    "for i in range(SIZE):\n",
    "    if (i in adv_evo_strategy) and (i in adv_evo_strategy_lgb):\n",
    "        if adv_evo_strategy[i].is_perturbed() and adv_evo_strategy_lgb[i].is_perturbed():\n",
    "            common_perturbed_indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adv_evo_strategy_deep_shared = [adv_evo_strategy[x] for x in common_perturbed_indices]\n",
    "adv_evo_strategy_lgb_shared = [adv_evo_strategy_lgb[x] for x in common_perturbed_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evoba_stats_deep_shared = utils.get_evoba_stats(adv_evo_strategy_deep_shared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evoba_stats_lgb_shared = utils.get_evoba_stats(adv_evo_strategy_lgb_shared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "utils.print_evoba_stats(evoba_stats_deep_shared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "utils.print_evoba_stats(evoba_stats_lgb_shared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_IMG_PLOT_COMPARISON = 12\n",
    "fig, axs = plt.subplots(nrows=3, ncols=NUM_IMG_PLOT_COMPARISON, figsize=(3 * NUM_IMG_PLOT_COMPARISON, 11))\n",
    "for i in range(NUM_IMG_PLOT_COMPARISON):\n",
    "    IDX = random.randint(0, len(adv_evo_strategy_deep_shared))\n",
    "    \n",
    "    original_label = adv_evo_strategy_deep_shared[IDX].label\n",
    "    \n",
    "    axs[0][i].set_title(f\"{cifar_100_classes[original_label]}\")\n",
    "    axs[0][i].imshow(adv_evo_strategy_deep_shared[IDX].img)\n",
    "    \n",
    "    axs[0][0].set_ylabel(\"Original image\", fontsize=14)\n",
    "\n",
    "    \n",
    "    pred_class_lgb = stacked_model.predict(np.array([adv_evo_strategy_lgb_shared[IDX].get_best_candidate()]))[0]\n",
    "    pred_class_lgb = np.argmax(pred_class_lgb)\n",
    "    axs[1][i].set_title(f\"{cifar_100_classes[pred_class_lgb]}\")\n",
    "    axs[1][i].imshow(adv_evo_strategy_lgb_shared[IDX].get_best_candidate())\n",
    "    \n",
    "    axs[1][0].set_ylabel(\"Ensemble perturbed iamge\", fontsize=14)\n",
    "\n",
    "    \n",
    "    pred_class_deep = model.predict(np.array([adv_evo_strategy_deep_shared[IDX].get_best_candidate()]))[0]\n",
    "    pred_class_deep = np.argmax(pred_class_deep)\n",
    "    axs[2][i].set_title(f\"{cifar_100_classes[pred_class_deep]}\")\n",
    "    axs[2][i].imshow(adv_evo_strategy_deep_shared[IDX].get_best_candidate())\n",
    "\n",
    "    axs[2][0].set_ylabel(\"Deep perturbed iamge\", fontsize=14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Visualise robust vs non-robust image embeddings [deprecated for now, to review after changes in the way EvoBA loops are ran] </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_interm_features = stacked_model.predict_intermediary(x_test_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: try UMAP\n",
    "X_embedded = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=3).fit_transform(test_interm_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_embedded_x = [x[0] for x in X_embedded]\n",
    "X_embedded_y = [x[1] for x in X_embedded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test_class = np.argmax(y_test_correct, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Only plot first couple classes embeddings\n",
    "class_plot_list = list(range(100))\n",
    "class_to_idx_dict = {c: i for i, c in enumerate(class_plot_list)}\n",
    "sample_mask = [x in class_plot_list for x in y_test_class]\n",
    "\n",
    "X_embedded_x_sample = np.array(X_embedded_x)[sample_mask]\n",
    "X_embedded_y_sample = np.array(X_embedded_y)[sample_mask]\n",
    "y_test_sample = y_test_correct[sample_mask]\n",
    "y_test_class_sample = np.argmax(y_test_sample, axis=1)\n",
    "\n",
    "# color_list = [class_to_idx_dict[c] for c in y_test_class_sample]\n",
    "# color_list = [1 for c in y_test_class_sample]\n",
    "color_list = [int(class_to_idx_dict[c]/20) for c in y_test_class_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_hard_perturbed_lgb = np.logical_or(np.array(queries_lgb) > 10000, np.array(queries_lgb) < 0)\n",
    "mask_easy_perturbed_lgb = np.logical_and(np.array(queries_lgb) > 0, np.array(queries_lgb) < 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_robust = np.logical_and(sample_mask[:SIZE], mask_hard_perturbed_lgb)\n",
    "\n",
    "X_embedded_x_sample_robust = np.array(X_embedded_x)[:SIZE][mask_robust]\n",
    "X_embedded_y_sample_robust = np.array(X_embedded_y)[:SIZE][mask_robust]\n",
    "y_test_sample_robust = y_test_correct[:SIZE][mask_robust]\n",
    "y_test_class_sample_robust = np.argmax(y_test_sample_robust, axis=1)\n",
    "\n",
    "# color_list_robust = [class_to_idx_dict[c] + 10 for c in y_test_class_sample_robust]\n",
    "# color_list_robust = [int(class_to_idx_dict[c]/50) for c in y_test_class_sample_robust]\n",
    "color_list_robust = [0 for c in y_test_class_sample_robust]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_not_robust = np.logical_and(sample_mask[:SIZE], mask_easy_perturbed_lgb)\n",
    "\n",
    "X_embedded_x_sample_not_robust = np.array(X_embedded_x)[:SIZE][mask_not_robust]\n",
    "X_embedded_y_sample_not_robust = np.array(X_embedded_y)[:SIZE][mask_not_robust]\n",
    "y_test_sample_not_robust = y_test_correct[:SIZE][mask_not_robust]\n",
    "y_test_class_sample_not_robust = np.argmax(y_test_sample_not_robust, axis=1)\n",
    "\n",
    "color_list_not_robust = [class_to_idx_dict[c] + 10 for c in y_test_class_sample_not_robust]\n",
    "color_list_not_robust = [0 for c in y_test_class_sample_not_robust]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_embedded_x_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(X_embedded_x_sample_not_robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(X_embedded_x_sample_robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(queries_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,30))\n",
    "sns.scatterplot(x=X_embedded_x_sample, y=X_embedded_y_sample, hue=color_list)\n",
    "sns.scatterplot(x=X_embedded_x_sample_robust, y=X_embedded_y_sample_robust, hue=color_list_robust, marker=\"X\", s=100, alpha=0.9)\n",
    "# sns.scatterplot(x=X_embedded_x_sample_not_robust, y=X_embedded_y_sample_not_robust, hue=color_list_not_robust, marker=\"X\", s=100, alpha=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_hard_perturbed_lgb = np.logical_or(np.array(queries_lgb) > 1000, np.array(queries_lgb) <0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_hard_perturbed = np.logical_or(np.array(queries) > 1000, np.array(queries)<0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf] *",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
